{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.augmentation import RNNDataset\n",
    "from tradeforecast.viz import plot_rnn_forecasts\n",
    "from tradeforecast.forecast.base import LitBase\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning import Trainer\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict(model: LitBase, data_loader: DataLoader, dataset: RNNDataset):\n",
    "    y: Tensor; y_pred: Tensor\n",
    "    y, y_pred = model.predict(data_loader)\n",
    "    y = dataset.inverse_transform(y.numpy())\n",
    "    y_pred = dataset.inverse_transform(y_pred.numpy())\n",
    "    plot_rnn_forecasts(y, y_pred)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.augmentation import DataEntryPoint, Indicators, FeatureEngg\n",
    "from tradeforecast.scrape import Scrapper\n",
    "\n",
    "ticker = 'GOOG'\n",
    "scrapper = Scrapper(ticker)\n",
    "\n",
    "df_dict = scrapper.fetch_historic_data(interval='1d', start='2015-01-01', end='2024-12-06')\n",
    "\n",
    "data_entry = DataEntryPoint(df=df_dict[ticker])\n",
    "\n",
    "indicators = Indicators(data_entry)\n",
    "indicators.add_moving_average().add_moving_average(n=30).add_macd_sl().add_rsi().add_atr()\n",
    "\n",
    "features = FeatureEngg(data_entry)\n",
    "features.add_quarters().add_weeks()\n",
    "\n",
    "lf = data_entry.data.drop_nulls().drop('High','Low')\n",
    "lf.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.augmentation import train_val_test_split\n",
    "\n",
    "dataset_kwargs = {'lf': lf,\n",
    "                 'non_temporal': [x for x in data_entry.non_temporal if x not in ['High', 'Low']],\n",
    "                 'temporal': data_entry.temporal,\n",
    "                 'target': 'Close',\n",
    "                 'look_back_len': 60,\n",
    "                 'forecast_len': 5}\n",
    "\n",
    "rnn_dataset = RNNDataset(**dataset_kwargs)\n",
    "\n",
    "train_dataset, test_dataset = train_val_test_split(rnn_dataset, test_size=0.1)\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.forecast import LSTM\n",
    "from tradeforecast.forecast.utils import OverrideEpochStepCallback\n",
    "\n",
    "lstm_kwargs = {'input_size': len(rnn_dataset.features),\n",
    "              'hidden_size': 32,\n",
    "              'n_LSTM': 2,\n",
    "              'bidirectional': False,\n",
    "              'fc_out_size':[],\n",
    "              'output_size': rnn_dataset.forecast_len,\n",
    "              'dropout': 0,\n",
    "              'criterion': F.mse_loss,\n",
    "              'lr': 0.1,\n",
    "              'optimizer': optim.SGD}\n",
    "\n",
    "lstm_model = LSTM(**lstm_kwargs)\n",
    "\n",
    "lstm_trainer = Trainer(fast_dev_run=False, max_epochs=1000, log_every_n_steps=10, check_val_every_n_epoch=100)\n",
    "\n",
    "lstm_trainer.fit(lstm_model, train_dataloaders=train_loader)\n",
    "\n",
    "train_loss: Tensor = lstm_trainer.callback_metrics.get('train/loss', None)\n",
    "train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainer.test(lstm_model, test_loader)\n",
    "\n",
    "test_loss: Tensor = lstm_trainer.callback_metrics.get('test/loss', None)\n",
    "test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(lstm_model, train_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(lstm_model, test_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = lstm_model.save_model_state(ticker_interval='AAPL_1d')\n",
    "model_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ConvLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.forecast import ConvLSTM\n",
    "\n",
    "clstm_kwargs = {'input_size': len(rnn_dataset.features),\n",
    "            'conv_out_size': len(rnn_dataset.features)*2,\n",
    "            'kernel_size': rnn_dataset.forecast_len,\n",
    "            'hidden_size': 32,\n",
    "            'n_LSTM': 2,\n",
    "            'bidirectional': False,\n",
    "            'fc_out_size':[],\n",
    "            'output_size': rnn_dataset.forecast_len,\n",
    "            'dropout': 0,\n",
    "            'criterion': F.mse_loss,\n",
    "            'lr': 0.1,\n",
    "            'optimizer': optim.SGD}\n",
    "\n",
    "clstm_model = ConvLSTM(**clstm_kwargs)\n",
    "\n",
    "clstm_trainer = Trainer(fast_dev_run=False, max_epochs=1000, log_every_n_steps=10, check_val_every_n_epoch=100)\n",
    "\n",
    "clstm_trainer.fit(clstm_model, train_dataloaders=train_loader)\n",
    "\n",
    "train_loss: Tensor = clstm_trainer.callback_metrics.get('train/loss', None)\n",
    "train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstm_trainer.test(clstm_model, test_loader)\n",
    "\n",
    "test_loss: Tensor = clstm_trainer.callback_metrics.get('test/loss', None)\n",
    "test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clstm_model, train_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clstm_model, test_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = clstm_model.save_model_state(ticker_interval='AAPL_1d')\n",
    "model_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EncTransformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeforecast.forecast import EncTransformer\n",
    "\n",
    "et_kwargs = {'input_size': len(rnn_dataset.features),\n",
    "            'nhead': 4,\n",
    "            'd_model': 64,\n",
    "            'num_layers': 2,\n",
    "            'output_size': rnn_dataset.forecast_len,\n",
    "            'dropout': 0,\n",
    "            'criterion': F.mse_loss,\n",
    "            'lr': 0.1,\n",
    "            'optimizer': optim.SGD}\n",
    "\n",
    "et_model = EncTransformer(**et_kwargs)\n",
    "\n",
    "et_trainer = Trainer(fast_dev_run=False, max_epochs=1000, log_every_n_steps=10, check_val_every_n_epoch=100)\n",
    "\n",
    "et_trainer.fit(et_model, train_dataloaders=train_loader)\n",
    "\n",
    "train_loss: Tensor = et_trainer.callback_metrics.get('train/loss', None)\n",
    "train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_trainer.test(et_model, test_loader)\n",
    "\n",
    "test_loss: Tensor = et_trainer.callback_metrics.get('test/loss', None)\n",
    "test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(et_model, train_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(et_model, test_loader, rnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = et_model.save_model_state(ticker_interval='AAPL_1d')\n",
    "model_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
